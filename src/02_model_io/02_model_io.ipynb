{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='こんにちは！元気ですか？何かお手伝いできることはありますか？'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "result: BaseMessage = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはどこの会社が開発した製品ですか？\n",
      "Xperiaはどこの会社が開発した製品ですか？\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\"product\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"iPhone\"))\n",
    "print(prompt.format(product=\"Xperia\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはアメリカの企業であるApple（アップル）が開発した製品です。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\"product\"],\n",
    ")\n",
    "\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか?\",\n",
    "    input_variables=[\"product\"],\n",
    ")\n",
    "\n",
    "prompt.save(Path(Path.cwd(), \"prompt.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはどこの会社が開発した製品ですか?\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "loaded_prompt = load_prompt(Path(Path.cwd(), \"prompt.json\"))\n",
    "\n",
    "print(loaded_prompt.format(product=\"iPhone\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美味しいステーキを焼くための基本的な手順を以下に示します。\n",
      "\n",
      "1. ステーキを室温に戻す：ステーキを冷蔵庫から出して、室温に戻します。これにより、肉の中心部まで均等に火が通りやすくなります。\n",
      "\n",
      "2. ステーキに塩とコショウを振る：ステーキの両面に塩とコショウを振ります。ここで塩を振ることで、肉の旨味を引き立てることができます。\n",
      "\n",
      "3. フライパンを予熱する：フライパンを中火にかけて、しっかりと予熱します。ステーキを焼く際に、フライパンが熱いうちに入れることで焼きムラを防ぐことができます。\n",
      "\n",
      "4. ステーキを焼く：フライパンにステーキを入れ、両面を焼きます。焼き加減はお好みで調整してくださいが、一般的にはレア、ミディアム、ウェルダンの３段階があります。\n",
      "\n",
      "5. 休ませる：ステーキを焼いた後は、アルミホイルで包んで数分休ませます。これにより、肉汁がしっかりと染み込み、よりジューシーな仕上がりになります。\n",
      "\n",
      "以上が、美味しいステーキの焼き方の基本的な手順です。焼き加減や調味料はお好みで調整して、あなたが一番美味しいと思うステーキを焼いてみてください。"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    streaming=True,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "resp = chat.invoke(input=[HumanMessage(content=\"おいしいステーキの焼き方を教えて\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！元気ですか？何かお手伝いできることがありましたらお知らせくださいね。\n",
      "実行時間: 1.1980574131011963秒\n",
      "こんにちは！元気ですか？何かお手伝いできることがありましたらお知らせくださいね。\n",
      "実行時間: 0.0018334388732910156秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "start = time.time()\n",
    "result = chat.invoke([HumanMessage(content=\"こんにちは！\")])\n",
    "\n",
    "end = time.time()\n",
    "print(result.content)\n",
    "print(f\"実行時間: {end - start}秒\")\n",
    "\n",
    "start = time.time()\n",
    "result = chat.invoke([HumanMessage(content=\"こんにちは！\")])\n",
    "\n",
    "end = time.time()\n",
    "print(result.content)\n",
    "print(f\"実行時間: {end - start}秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "楽しんでください\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "result = llm.invoke(\n",
    "    \"美味しいラーメンを\",\n",
    "    stop=[\"。\"],\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatted_prompt: 以下は句読点の抜けた入力に句読点を追加してください。追加して良い句読点は「、」「。」のみです。他の句読点は追加しないでください。\n",
      "\n",
      "入力: LangChainはChatGPT・Large Language Model (LLM)の実利用をより柔軟に簡易に行うためのツール群です\n",
      "出力: LangChainは、ChatGPT・Large Language Model (LLM)の実利用をより柔軟に、安易に行うためのツール群です\n",
      "\n",
      "入力: 私は様々な機能がモジュールとして提供されているLangChainを使ってアプリケーションを開発しています\n",
      "出力: \n",
      "result: 私は、様々な機能がモジュールとして提供されているLangChainを使って、アプリケーションを開発しています。\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"LangChainはChatGPT・Large Language Model (LLM)の実利用をより柔軟に簡易に行うためのツール群です\",\n",
    "        \"output\": \"LangChainは、ChatGPT・Large Language Model (LLM)の実利用をより柔軟に、安易に行うためのツール群です\",\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=prompt,\n",
    "    prefix=\"以下は句読点の抜けた入力に句読点を追加してください。追加して良い句読点は「、」「。」のみです。他の句読点は追加しないでください。\",\n",
    "    suffix=\"入力: {input_string}\\n出力: \",\n",
    "    input_variables=[\"input_string\"],\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "formatted_prompt = few_shot_prompt.format(\n",
    "    input_string=\"私は様々な機能がモジュールとして提供されているLangChainを使ってアプリケーションを開発しています\"\n",
    ")\n",
    "result = llm.invoke(formatted_prompt)\n",
    "\n",
    "print(f\"formatted_prompt: {formatted_prompt}\")\n",
    "print(f\"result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代表的な製品 => iPhone\n",
      "代表的な製品 => iPad\n",
      "代表的な製品 => MacBook\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Appleが開発した代表的な製品を3つ教えてください\"),\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "output = output_parser.parse(str(result.content))\n",
    "\n",
    "for item in output:\n",
    "    print(f\"代表的な製品 => {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445-12-03 22:45:54.013232\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "prompt: PromptTemplate = PromptTemplate.from_template(\"{product}のリリース日を教えて\")\n",
    "\n",
    "result: BaseMessage = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone8\")),\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "output: datetime = output_parser.parse(str(result.content))\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名: Samsung Galaxy S21 Ultra\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "class Smartphone(BaseModel):\n",
    "    release_date: str = Field(description=\"スマートフォンの発売日\")\n",
    "    screen_inches: float = Field(description=\"スマートフォンの画面サイズ（インチ）\")\n",
    "    os_installed: str = Field(description=\"スマートフォンにインストールされているOS\")\n",
    "    sp_model_name: str = Field(description=\"スマートフォンのモデル名\")\n",
    "\n",
    "    @validator(\"screen_inches\")\n",
    "    def validate_screen_inches(cls, field):\n",
    "        if field <= 0:\n",
    "            raise ValueError(\"Screen inches must be positive number\")\n",
    "        return field\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Smartphone)\n",
    "\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Androidでリリースしたスマートフォンを1個挙げて\"),\n",
    "        HumanMessage(content=parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parsed_result = parser.parse(str(result.content))\n",
    "\n",
    "print(f\"モデル名: {parsed_result.sp_model_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
