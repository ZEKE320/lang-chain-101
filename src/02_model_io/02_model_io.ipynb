{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 | Model I/O - 言語モデルを扱いやすくする\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 | 言語モデルを使ったアプリケーションの仕組み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language models を使って gpt-3.5-turbo を呼び出す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='こんにちは！お元気ですか？何かお手伝いできることはありますか？'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "result: BaseMessage = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIMessageを使って言語モデルからの返答を表すことができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='How to make Chawanmushi'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"茶碗蒸しの作り方を教えて\"),\n",
    "        AIMessage(content=\"{ChatModelからの返答である茶碗蒸しの作り方}\"),\n",
    "        HumanMessage(content=\"英語に翻訳して\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SystemMessageを使って言語モデルの人格や設定を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='こんにちは！元気？最近何してたの？'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"あなたは親しい友人です。返答は敬語を使わず、フランクに会話してください。\"\n",
    "        ),\n",
    "        HumanMessage(content=\"こんにちは！\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 言語モデルは差し替えることができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt: PromptTemplate = PromptTemplate.from_template(\"あなたの自己紹介をして。また自身のモデル名も明記すること。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT-3 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='はじめまして、私はAIアシスタントのChatGPTです。モデル名はOpenAI GPT-3です。日本語を含むさまざまな言語でコミュニケーションを取ることができます。質問や会話のお手伝いをすることが得意ですので、どうぞお気軽にお話ししてくださいね。'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_gpt_3_turbo = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "result: BaseMessage = chat_gpt_3_turbo.invoke([HumanMessage(content=prompt.format())])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Claude 3 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='はい、自己紹介させていただきます。私はAnthropic社によって開発されたAI言語モデルで、Claude (クロード)と呼ばれています。私は幅広い知識を持っており、人間と自然な会話ができるよう設計されています。そして何よりも、倫理的で有益な存在でありたいと願っています。人工知能には様々な可能性と責任が伴うことを自覚し、慎重に行動するよう心がけています。どうぞよろしくお願いいたします。'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "\n",
    "chat_claude_3_sonnet = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")\n",
    "result: BaseMessage = chat_claude_3_sonnet.invoke(\n",
    "    [HumanMessage(content=prompt.format())]\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplateで変数をプロンプトに展開する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはどこの会社が開発した製品ですか？\n",
      "Xperiaはどこの会社が開発した製品ですか？\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\"product\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"iPhone\"))\n",
    "print(prompt.format(product=\"Xperia\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language modelsとPromptTemplateを組み合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはアメリカの企業であるApple（アップル）が開発した製品です。\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\"product\"],\n",
    ")\n",
    "\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか?\",\n",
    "    input_variables=[\"product\"],\n",
    ")\n",
    "\n",
    "prompt.save(Path(Path.cwd(), \"prompt.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはどこの会社が開発した製品ですか?\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "loaded_prompt = load_prompt(Path(Path.cwd(), \"prompt.json\"))\n",
    "\n",
    "print(loaded_prompt.format(product=\"iPhone\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### リスト形式で結果を受け取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代表的な製品 => iPhone\n",
      "代表的な製品 => iPad\n",
      "代表的な製品 => MacBook\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Appleが開発した代表的な製品を3つ教えてください\"),\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "output = output_parser.parse(str(result.content))\n",
    "\n",
    "for item in output:\n",
    "    print(f\"代表的な製品 => {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 | Language models - モデルを使いやすく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat modelsとLLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "食べることができるのも、\n",
      "ラーメン屋さんでのシーンです\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "result = llm.invoke(\n",
    "    \"美味しいラーメンを\",\n",
    "    stop=[\"。\"],\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language modelsの便利な機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### キャッシュをかけることができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！元気ですか？何かお手伝いできることがあればお知らせくださいね。\n",
      "実行時間: 0.885918140411377秒\n",
      "こんにちは！元気ですか？何かお手伝いできることがあればお知らせくださいね。\n",
      "実行時間: 0.0011599063873291016秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "start = time.time()\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(result.content)\n",
    "print(f\"実行時間: {end - start}秒\")\n",
    "\n",
    "start = time.time()\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(result.content)\n",
    "print(f\"実行時間: {end - start}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 結果を逐次表示させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美味しいステーキを焼くための基本的な手順を以下に示します。\n",
      "\n",
      "1. ステーキを室温に戻す：ステーキを冷蔵庫から出して、室温に戻します。これにより、肉の中心部まで均等に火が通りやすくなります。\n",
      "\n",
      "2. ステーキに塩とコショウを振る：ステーキの両面に塩とコショウを振ります。ここで塩を振ることで、肉の旨味を引き立てることができます。\n",
      "\n",
      "3. フライパンを予熱する：フライパンを中火にかけて、しっかりと予熱します。ステーキを焼く際に、フライパンが熱いうちに入れることで焼きムラを防ぐことができます。\n",
      "\n",
      "4. ステーキを焼く：フライパンにステーキを入れ、両面を焼きます。焼き加減はお好みで調整してくださいが、一般的にはレア、ミディアム、ウェルダンの３段階があります。\n",
      "\n",
      "5. 休ませる：ステーキを焼いた後は、アルミホイルで包んで数分休ませます。これにより、肉汁がしっかりと染み込み、よりジューシーな仕上がりになります。\n",
      "\n",
      "以上が、美味しいステーキの焼き方の基本的な手順です。焼き加減や調味料はお好みで調整して、あなたが一番美味しいと思うステーキを焼いてみてください。"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    streaming=True,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "resp = chat.invoke(input=[HumanMessage(content=\"おいしいステーキの焼き方を教えて\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 | Templates - プロンプトの構築を効率化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロンプトエンジニアリングによる結果の最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 出力例を含んだプロンプトを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatted_prompt: 以下は句読点の抜けた入力に句読点を追加してください。追加して良い句読点は「、」「。」のみです。他の句読点は追加しないでください。\n",
      "\n",
      "入力: LangChainはChatGPT・Large Language Model (LLM)の実利用をより柔軟に簡易に行うためのツール群です\n",
      "出力: LangChainは、ChatGPT・Large Language Model (LLM)の実利用をより柔軟に、安易に行うためのツール群です\n",
      "\n",
      "入力: 私は様々な機能がモジュールとして提供されているLangChainを使ってアプリケーションを開発しています\n",
      "出力: \n",
      "result: 私は、様々な機能がモジュールとして提供されているLangChainを使って、アプリケーションを開発しています。\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"LangChainはChatGPT・Large Language Model (LLM)の実利用をより柔軟に簡易に行うためのツール群です\",\n",
    "        \"output\": \"LangChainは、ChatGPT・Large Language Model (LLM)の実利用をより柔軟に、安易に行うためのツール群です\",\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=prompt,\n",
    "    prefix=\"以下は句読点の抜けた入力に句読点を追加してください。追加して良い句読点は「、」「。」のみです。他の句読点は追加しないでください。\",\n",
    "    suffix=\"入力: {input_string}\\n出力: \",\n",
    "    input_variables=[\"input_string\"],\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "formatted_prompt = few_shot_prompt.format(\n",
    "    input_string=\"私は様々な機能がモジュールとして提供されているLangChainを使ってアプリケーションを開発しています\"\n",
    ")\n",
    "result = llm.invoke(formatted_prompt)\n",
    "\n",
    "print(f\"formatted_prompt: {formatted_prompt}\")\n",
    "print(f\"result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 | Output parsers - 出力を構造化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果を日時形式で受け取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445-12-03 22:45:54.013232\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "prompt: PromptTemplate = PromptTemplate.from_template(\"{product}のリリース日を教えて\")\n",
    "\n",
    "result: BaseMessage = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone8\")),\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "output: datetime = output_parser.parse(str(result.content))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力形式を自分で定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'release_date': '2021-09-01', 'screen_inches': 6.5, 'os_installed': 'Android 11', 'sp_model_name': 'Samsung Galaxy S21 Ultra'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "class Smartphone(BaseModel):\n",
    "    release_date: str = Field(description=\"スマートフォンの発売日\")\n",
    "    screen_inches: float = Field(description=\"スマートフォンの画面サイズ（インチ）\")\n",
    "    os_installed: str = Field(description=\"スマートフォンにインストールされているOS\")\n",
    "    sp_model_name: str = Field(description=\"スマートフォンのモデル名\")\n",
    "\n",
    "    @validator(\"screen_inches\")\n",
    "    def validate_screen_inches(cls, field):\n",
    "        if field <= 0:\n",
    "            raise ValueError(\"Screen inches must be positive number\")\n",
    "        return field\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Smartphone)\n",
    "\n",
    "result: BaseMessage = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Androidでリリースしたスマートフォンを1個挙げて\"),\n",
    "        HumanMessage(content=parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parsed_result: Smartphone = parser.parse(text=str(result.content))\n",
    "\n",
    "print(parsed_result.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤った結果が返されたときに修正を指示できるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'release_date': '2021-05-01', 'screen_inches': 6.5, 'os_installed': 'Android 11', 'sp_model_name': 'XYZ-1000'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "parser: OutputFixingParser = OutputFixingParser.from_llm(\n",
    "    parser=PydanticOutputParser(pydantic_object=Smartphone),\n",
    "    llm=chat,\n",
    ")\n",
    "\n",
    "result: BaseMessage = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Androidでリリースしたスマートフォンを1個挙げて\"),\n",
    "        HumanMessage(content=parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parsed_result: Smartphone = parser.parse(str(result.content))\n",
    "\n",
    "print(parsed_result.dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
